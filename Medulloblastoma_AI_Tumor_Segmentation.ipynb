{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katarina-ku/medulloblastoma/blob/main/Medulloblastoma_AI_Tumor_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MB-AI Tumor Segmentation\n"
      ],
      "metadata": {
        "id": "lPoAKzI67m2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: To revert to the default mode, first delete the `nnUNetData/` folder from your Google Drive (https://drive.google.com/drive/u/0/my-drive). After doing so, re-run the process.\""
      ],
      "metadata": {
        "id": "l8yIb7jVnEs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1: Prepare"
      ],
      "metadata": {
        "id": "BW48FvsMeBQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 (Prepare): Please navigate to the '**Runtime**' option in your toolbar, select '**Change Runtime Type**', and then choose **a GPU** (for instance, **a T4 GPU**). This change is necessary to run the deep learning model."
      ],
      "metadata": {
        "id": "9UKnDY7K_Tzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 (Prepare): Install PyTorch and nnUNet-version1 (approximately 1 minute)."
      ],
      "metadata": {
        "id": "0z6HeB0s74ln"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBGSZId9UpyB"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!git clone https://github.com/MIC-DKFZ/nnUNet.git\n",
        "!cd nnUNet && git checkout nnunetv1 && pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 (Prepare): Mount your google drive. Note: your google drive will only be accessible in your current Colab session, hosted by Google."
      ],
      "metadata": {
        "id": "WmmOcBKT8Jxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "95M0Fh0TXK2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 (Prepare): Create nnUNet work directory and download the pretrained weights to your google drive (approximately 2 minutes)."
      ],
      "metadata": {
        "id": "2YUz94s88WAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create work directory necessary for running nnUNet\n",
        "!cd /content/drive/MyDrive/ && mkdir -p ./nnUNetData/ ./nnUNetData/nnUNet_raw_data/ ./nnUNetData/nnUNet_preprocessed/\n",
        "\n",
        "# download the pretrained weights of nnUNet to your google drive\n",
        "!filename='/content/drive/MyDrive/nnUNetData/RESULTS_FOLDER.zip' && fileid='1cyy9LdzYCXD9PJbI2FIhuwzIeGj2Av0q' && \\\n",
        " wget --load-cookies /tmp/cookies.txt \"https://drive.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/uc?export=download&id=${fileid}' -O- | sed -rn 's/.confirm=([0-9A-Za-z_]+)./\\1\\n/p')&id=${fileid}\" -O ${filename} && rm -rf /tmp/cookies.txt\n",
        "\n",
        "# decompress the zip folder and move everything to nnUNetData directory\n",
        "!cd /content/drive/MyDrive/ && unzip ./nnUNetData/RESULTS_FOLDER.zip -d ./nnUNetData/ && rm -r ./nnUNetData/__MACOSX/ && rm ./nnUNetData/RESULTS_FOLDER.zip"
      ],
      "metadata": {
        "id": "p2YEPORHYFVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 (Prepare): Download the five testing subjects and place them under the `testing_examples` directory in your google drive (approximately less than 1 minute)."
      ],
      "metadata": {
        "id": "YrBxVbzV85o9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create nnUNet_raw_data folder\n",
        "!cd /content/drive/MyDrive/nnUNetData/nnUNet_raw_data/ && mkdir ./Task505_MedoNative/\n",
        "\n",
        "# download the testing images (5 MB subjects with T1E and T2 nifti files)\n",
        "!filename='/content/drive/MyDrive/nnUNetData/testing_examples.zip' && fileid='1eCQaBCdfb7xX-jzePx-t3NMH2FbUBsYi' && \\\n",
        " wget --load-cookies /tmp/cookies.txt \"https://drive.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/uc?export=download&id=${fileid}' -O- | sed -rn 's/.confirm=([0-9A-Za-z_]+)./\\1\\n/p')&id=${fileid}\" -O ${filename} && rm -rf /tmp/cookies.txt\n",
        "\n",
        "# decompress the zip folder and move the testing subjects to nnUNet_raw_data directiory\n",
        "!cd /content/drive/MyDrive/nnUNetData/ && unzip ./testing_examples.zip -d ./ && rm -r ./__MACOSX/ && rm ./testing_examples.zip"
      ],
      "metadata": {
        "id": "vQ98j5JbY5oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2: Inference"
      ],
      "metadata": {
        "id": "8Q8hYUov4s-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segment the tumor area in the five test samples (approximately 5 minutes using a T4 GPU, your patience is appreciated)."
      ],
      "metadata": {
        "id": "qFX6d2jW7Dtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export nnUNet_raw_data_base=\"/content/drive/MyDrive/nnUNetData\" && \\\n",
        " export nnUNet_preprocessed=\"/content/drive/MyDrive/nnUNetData/nnUNet_preprocessed\" && \\\n",
        " export RESULTS_FOLDER=\"/content/drive/MyDrive/nnUNetData/RESULTS_FOLDER\" && \\\n",
        " mkdir -p /content/drive/MyDrive/nnUNetData/predicted_segmentations/ && \\\n",
        " nnUNet_predict -i /content/drive/MyDrive/nnUNetData/testing_examples/ \\\n",
        "                -o /content/drive/MyDrive/nnUNetData/predicted_segmentations/ -t 505 -m 3d_fullres"
      ],
      "metadata": {
        "id": "mohqbaYkt3pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 3: Visualization"
      ],
      "metadata": {
        "id": "k36zpptz7Gbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the slice and segmentation that displays the largest tumor area."
      ],
      "metadata": {
        "id": "iPSCZmFg9zOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "examples_list = ['Native_001', 'Native_002', 'Native_003', 'Native_004', 'Native_005']\n",
        "order2subtypes = {'001': 'WNT', '002': 'SHH TP53-', '003': 'SHH TP53+', '004': 'Group 3', '005': 'Group 4'}\n",
        "images_dir = '/content/drive/MyDrive/nnUNetData/testing_examples/'\n",
        "pred_labels_dir = '/content/drive/MyDrive/nnUNetData/predicted_segmentations/'\n",
        "\n",
        "\n",
        "# for visualization, identify the slice that displays the largest tumor area\n",
        "def find_max_slice(mask):\n",
        "    sums = [np.sum(mask[..., i]) for i in range(mask.shape[-1])]\n",
        "    return np.argmax(sums)\n",
        "\n",
        "\n",
        "for example in examples_list:\n",
        "    example_order = example.split('_')[-1]\n",
        "    subtype_label = order2subtypes[example_order]\n",
        "    t1e_image_path = os.path.join(images_dir, f'{example}_0000.nii.gz')\n",
        "    t2_image_path = os.path.join(images_dir, f'{example}_0001.nii.gz')\n",
        "    mask_path = os.path.join(pred_labels_dir, f'{example}.nii.gz')\n",
        "\n",
        "    t1e_img = nib.load(t1e_image_path).get_fdata()\n",
        "    t2_img = nib.load(t2_image_path).get_fdata()\n",
        "    mask_img = nib.load(mask_path).get_fdata()\n",
        "\n",
        "    max_slice = find_max_slice(mask_img)\n",
        "    fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
        "\n",
        "    plt.figtext(0.1, 0.5, subtype_label, fontsize=12, va='center', ha='right', rotation='vertical')\n",
        "\n",
        "    ax[0].imshow(t1e_img[..., max_slice], cmap='gray')\n",
        "    ax[0].set_title(f'Subject {example_order} T1E')\n",
        "\n",
        "    ax[1].imshow(t1e_img[..., max_slice], cmap='gray')\n",
        "    ax[1].imshow(mask_img[..., max_slice], alpha=0.5, cmap='Reds')\n",
        "    ax[1].set_title(f'Subject {example_order} T1E with segmentation')\n",
        "\n",
        "    ax[2].imshow(t2_img[..., max_slice], cmap='gray')\n",
        "    ax[2].set_title(f'Subject {example_order} T2')\n",
        "\n",
        "    ax[3].imshow(t2_img[..., max_slice], cmap='gray')\n",
        "    ax[3].imshow(mask_img[..., max_slice], alpha=0.5, cmap='Reds')\n",
        "    ax[3].set_title(f'Subject {example_order} T2 with segmentation')\n",
        "\n",
        "    ax[4].imshow(mask_img[..., max_slice], cmap='Reds')\n",
        "    ax[4].set_title(f'Subject {example_order} Segmentation mask')\n",
        "\n",
        "    for a in ax:\n",
        "        a.axis('off')\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "9w33gbp31VpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Visualization***: To visualize the complete segmentation, you can download both the subject images and segmentation predictions to your local computer from specific directories in your Google Drive at https://drive.google.com/drive/u/0/my-drive. For subject images, navigate to `nnUNetData/testing_examples/`, and for the segmentation predictions, go to `nnUNetData/predicted_segmentations/`."
      ],
      "metadata": {
        "id": "W82sFhhi5Tfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 4: Run the model in your MRI Data"
      ],
      "metadata": {
        "id": "2tHlhTF0Bz_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 (Run in your data): Create the directory for saving your MRI Data."
      ],
      "metadata": {
        "id": "3b82q50i5dMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/nnUNetData/ && mkdir ./your_testing_examples/"
      ],
      "metadata": {
        "id": "xAe2H0Qf5hTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 (Run in your data): Upload your MRI data. Please follow the established naming conventions specified by the deep learning model."
      ],
      "metadata": {
        "id": "lQbwMKmE6ABU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adhere to the **naming conventions** when preparing your files. Please name T1E images as Native_YourSubjectID_0000.nii.gz and T2 images as Native_YourSubjectID_0001.nii.gz. Once named correctly, upload these files to the nnUNetData/your_testing_examples directory in your Google Drive, accessible at https://drive.google.com/drive/u/0/my-drive. After completing the upload, you can proceed with the prediction process.\n",
        "\n"
      ],
      "metadata": {
        "id": "3EJfoiF0Ce17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 (Run in your data): Predict the tumor segmentation in your data."
      ],
      "metadata": {
        "id": "ELTFyCeZ6qtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export nnUNet_raw_data_base=\"/content/drive/MyDrive/nnUNetData\" && \\\n",
        " export nnUNet_preprocessed=\"/content/drive/MyDrive/nnUNetData/nnUNet_preprocessed\" && \\\n",
        " export RESULTS_FOLDER=\"/content/drive/MyDrive/nnUNetData/RESULTS_FOLDER\" && \\\n",
        " mkdir -p /content/drive/MyDrive/nnUNetData/your_predicted_segmentations/ && \\\n",
        " nnUNet_predict -i /content/drive/MyDrive/nnUNetData/your_testing_examples/ \\\n",
        "                -o /content/drive/MyDrive/nnUNetData/your_predicted_segmentations/ -t 505 -m 3d_fullres"
      ],
      "metadata": {
        "id": "_FFgIHRW6fjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 (Run in your data): Download the segmentation masks for reviewing."
      ],
      "metadata": {
        "id": "1ejx7TtU7knC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can access the predicted segmentation masks in the `nnUNetData/your_predicted_segmentations/` folder on Google Drive at https://drive.google.com/drive/u/0/my-drive."
      ],
      "metadata": {
        "id": "BUhR2SmW71Hn"
      }
    }
  ]
}